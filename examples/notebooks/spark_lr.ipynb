
{
 "cells": [
      
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "showWarning();\n"
   ]

  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "var D = 10;   \/\/ Number of dimensions\n",
    "\n",
    "var file =  \".\/..\/data\/lr_data.txt\";\n",
    "var ITERATIONS =  10;\n"
   ]

  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "    var conf = new SparkConf().setAppName(\"JavaScript Logistic Regression\");\n",
    "    var sc = new SparkContext(conf);\n",
    "\n",
    "    var lines = sc.textFile(file);\n",
    "    var points = lines.map(function (line,D) {\n",
    "        var tok = line.split(\/\\s+\/);\n",
    "        var y = tok[0];\n",
    "        var x = [];\n",
    "        for (var i = 0; i < D; i++) {\n",
    "            x[i] = tok[i + 1];\n",
    "        }\n",
    "        return {x: x, y: y};\n",
    "\n",
    "    },[D]).cache();\n"
   ]

  },
   {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Initialize w to a random value\n"
   ]

  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    var weights = [];\n",
    "    var x = 1;\n",
    "    for (var i = 0; i < D; i++) {\n",
    "        weights[i] = 2 * Math.random() - 1;\n",
    "    }\n",
    "\n",
    "    print(\"Initial w: \");\n",
    "    printWeights(weights);\n",
    "\n",
    "    for (var i = 1; i <= ITERATIONS; i++) {\n",
    "        print(\"On iteration \" + i);\n",
    "        var gradient = points.map(function (datapoint, weights,D) {\n",
    "            var gradient = [];\n",
    "            for (var i = 0; i < D; i++) {\n",
    "               var d = 0;\n",
    "                for (var j = 0; j < D; j++) {\n",
    "                    d += weights[j] * datapoint.x[j];\n",
    "                }\n",
    "                gradient[i] = (1 \/ (1 + Math.exp(-datapoint.y * d)) - 1) * datapoint.y * datapoint.x[i];\n",
    "            }\n",
    "            return gradient;\n",
    "        }, [weights,D]).reduce(function (a, b,D) {\n",
    "            var result = [];\n",
    "            for (var j = 0; j < D; j++) {\n",
    "                result[j] = a[j] + b[j];\n",
    "            }\n",
    "            return result;\n",
    "        },[D]);\n",
    "\n",
    "        for (var j = 0; j < D; j++) {\n",
    "            weights[j] -= gradient[j];\n",
    "        }\n",
    "\n",
    "    }\n",
    "\n",
    "var result = weights;\n",
    "    print(\"Final w: \");\n",
    "    printWeights(result);\n",
    "    sc.stop();\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark 1.6.1 (Javascript)",
   "language": "javascript",
   "name": "eclair"
  },
  "language_info": {
   "name": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}