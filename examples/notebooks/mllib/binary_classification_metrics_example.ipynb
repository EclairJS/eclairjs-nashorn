
{
 "cells": [
      
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    var sparkConf = new SparkConf().setAppName(\"Binary Classification Metrics Test\");\n",
    "    var sc = new SparkContext(sparkConf);\n",
    "\n",
    "    var filename = ((typeof args !== \"undefined\") && (args.length > 1)) ?\n",
    "        args[1] : \"examples\/data\/mllib\/sample_binary_classification_data.txt\";\n",
    "\n",
    "    var data = MLUtils.loadLibSVMFile(sc, filename);\n"
   ]

  },
   {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into training (60%) and test (40%)\n"
   ]

  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    var split = data.randomSplit([0.6, 0.4], 11)\n",
    "    var training = split[0].cache();\n",
    "    var test = split[1];\n",
    "\n",
    "    var model = new LogisticRegressionWithLBFGS()\n",
    "        .setNumClasses(2)\n",
    "        .run(training);\n",
    "\n",
    "    var predictionAndLabels = test.mapToPair(function (lp, model) {\n",
    "        return new Tuple(model.predict(lp.getFeatures()), lp.getLabel());\n",
    "    }, [model]);\n",
    "\n",
    "    var metrics = new BinaryClassificationMetrics(predictionAndLabels);\n"
   ]

  },
   {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Precision by threshold\n"
   ]

  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    var precision = metrics.precisionByThreshold();\n",
    "    print(\"Precision by threshold: \" + precision.collect());\n"
   ]

  },
   {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Recall by threshold\n"
   ]

  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    var recall = metrics.recallByThreshold();\n",
    "    print(\"Recall by threshold: \" + recall.collect());\n"
   ]

  },
   {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " F Score by threshold\n"
   ]

  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    var f1Score = metrics.fMeasureByThreshold();\n",
    "    print(\"F1 Score by threshold: \" + f1Score.collect());\n",
    "\n",
    "    var f2Score = metrics.fMeasureByThreshold(2.0);\n",
    "    print(\"F2 Score by threshold: \" + f2Score.collect());\n"
   ]

  },
   {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Precision-recall curve\n"
   ]

  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    var prc = metrics.pr();\n",
    "    print(\"Precision-recall curve: \" + prc.collect());\n",
    "\n",
    "var result = true;\n",
    "\n",
    "    sc.stop();\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark 1.6.1 (Javascript)",
   "language": "javascript",
   "name": "eclair"
  },
  "language_info": {
   "name": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}