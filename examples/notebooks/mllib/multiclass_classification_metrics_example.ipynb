
{
 "cells": [
      
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    var sparkConf = new SparkConf().setAppName(\"Multi class Classification Metrics Example\");\n",
    "    var sc = new SparkContext(sparkConf);\n",
    "\n",
    "var path =  \"..\/data\/mllib\/sample_multiclass_classification_data.txt\";\n",
    "    var data = MLUtils.loadLibSVMFile(sc, path);\n"
   ]

  },
   {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Split initial RDD into two... [60% training data, 40% testing data].\n"
   ]

  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    var splits = data.randomSplit([0.6, 0.4], 11);\n",
    "    var training = splits[0].cache();\n",
    "    var test = splits[1];\n"
   ]

  },
   {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Run training algorithm to build the model.\n"
   ]

  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    var model = new LogisticRegressionWithLBFGS()\n",
    "        .setNumClasses(3)\n",
    "        .run(training);\n"
   ]

  },
   {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Compute raw scores on the test set.\n"
   ]

  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    var predictionAndLabels = test.map(function (lp, model) {\n",
    "        var prediction = model.predict(lp.getFeatures());\n",
    "        return new Tuple(prediction, lp.getLabel());\n",
    "    }, [model]);\n",
    "    var ret = {};\n",
    "    ret.model = model;\n"
   ]

  },
   {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Get evaluation metrics.\n"
   ]

  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    ret.metrics = new MulticlassMetrics(predictionAndLabels);\n",
    "\n",
    "var result = ret;\n"
   ]

  },
   {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Confusion matrix\n"
   ]

  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    var confusion = result.metrics.confusionMatrix();\n",
    "    print(\"Confusion matrix: \\n\" + confusion);\n"
   ]

  },
   {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Overall statistics\n"
   ]

  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    print(\"Precision = \" + result.metrics.precision());\n",
    "    print(\"Recall = \" + result.metrics.recall());\n",
    "    print(\"F1 Score = \" + result.metrics.fMeasure());\n"
   ]

  },
   {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Stats by labels\n"
   ]

  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    for (var i = 0; i < result.metrics.labels().length; i++) {\n",
    "        print(\"Class \" + result.metrics.labels()[i] + \" precision = \" + result.metrics.precision(result.metrics.labels()[i]));\n",
    "        print(\"Class \" + result.metrics.labels()[i] + \" recall = \" + result.metrics.recall(result.metrics.labels()[i]));\n",
    "        print(\"Class \" + result.metrics.labels()[i] + \" F1 score = \" + result.metrics.fMeasure(result.metrics.labels()[i]));\n",
    "    }\n"
   ]

  },
   {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weighted stats\n"
   ]

  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    print(\"Weighted precision = \" + result.metrics.weightedPrecision());\n",
    "    print(\"Weighted recall = \" + result.metrics.weightedRecall());\n",
    "    print(\"Weighted F1 score = \" + result.metrics.weightedFMeasure());\n",
    "    print(\"Weighted false positive rate = \" + result.metrics.weightedFalsePositiveRate());\n"
   ]

  },
   {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Save and load model\n"
   ]

  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    result.model.save(sc, \"target\/tmp\/LogisticRegressionModel\");\n",
    "    var sameModel = LogisticRegressionModel.load(sc, \"target\/tmp\/LogisticRegressionModel\");\n",
    "\n",
    "    sc.stop();\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark 1.6.1 (Javascript)",
   "language": "javascript",
   "name": "eclair"
  },
  "language_info": {
   "name": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}