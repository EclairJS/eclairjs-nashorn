
{
 "cells": [
      
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "    var sparkConf = new SparkConf().setAppName(\"Multilabel Classification Metrics Example\");\n",
    "    var sc = new SparkContext(sparkConf);\n",
    "    var metrics = run(sc);\n"
   ]

  },
   {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Summary stats\n"
   ]

  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    print(\"Recall = \" + metrics.recall());\n",
    "    print(\"Precision = \", +metrics.precision());\n",
    "    print(\"F1 measure = \", +metrics.f1Measure());\n",
    "    print(\"Accuracy = \", +metrics.accuracy());\n"
   ]

  },
   {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Stats by labels\n"
   ]

  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    for (var i = 0; i < metrics.labels().length - 1; i++) {\n",
    "        print(\"Class \" + metrics.labels()[i] + \" precision = \" +  metrics.precision(metrics.labels()[i]));\n",
    "        print(\"Class \" + metrics.labels()[i] + \" recall = \" + metrics.recall(metrics.labels()[i]));\n",
    "        print(\"Class \" + metrics.labels()[i] + \" F1 score = \" +  metrics.f1Measure(metrics.labels()[i]));\n",
    "    }\n"
   ]

  },
   {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Micro stats\n"
   ]

  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    print(\"Micro recall = \" + metrics.microRecall());\n",
    "    print(\"Micro precision = \" + metrics.microPrecision());\n",
    "    print(\"Micro F1 measure = \" + metrics.microF1Measure());\n"
   ]

  },
   {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Hamming loss\n"
   ]

  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    print(\"Hamming loss = \" + metrics.hammingLoss());\n"
   ]

  },
   {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Subset accuracy\n"
   ]

  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    print(\"Subset accuracy = \" + metrics.subsetAccuracy());\n",
    "\n",
    "    sc.stop();\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark 1.6.1 (Javascript)",
   "language": "javascript",
   "name": "eclair"
  },
  "language_info": {
   "name": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}