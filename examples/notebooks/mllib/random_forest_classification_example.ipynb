
{
 "cells": [
      
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "var sparkConf = new SparkConf()\n",
    "  .setAppName(\"Random Forest Classification Example\");\n",
    "\n",
    "var sc = new SparkContext(sparkConf);\n",
    "var datapath =  \"..\/data\/mllib\/sample_libsvm_data.txt\";\n",
    "\n",
    "var data = MLUtils.loadLibSVMFile(sc, datapath);\n"
   ]

  },
   {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Split the data into training and test sets (30% held out for testing)\n"
   ]

  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "var splits = data.randomSplit([0.7, 0.3]);\n",
    "var trainingData = splits[0];\n",
    "var testData = splits[1];\n"
   ]

  },
   {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Train a RandomForest model.\n",
    " Empty categoricalFeaturesInfo indicates all features are continuous.\n"
   ]

  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "var numClasses = 2;\n",
    "var categoricalFeaturesInfo = {};\n",
    "var numTrees = 3; \/\/ Use more in practice.\n",
    "var featureSubsetStrategy = \"auto\"; \/\/ Let the algorithm choose.\n",
    "var impurity = \"gini\";\n",
    "var maxDepth = 5;\n",
    "var maxBins = 32;\n",
    "var seed = 12345;\n"
   ]

  },
   {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Train a RandomForest model.\n"
   ]

  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "var model = RandomForest.trainClassifier(\n",
    "    trainingData,\n",
    "    numClasses,\n",
    "    categoricalFeaturesInfo, \n",
    "    numTrees, \n",
    "    featureSubsetStrategy, \n",
    "    impurity, \n",
    "    maxDepth, \n",
    "    maxBins, \n",
    "    seed\n",
    ");\n"
   ]

  },
   {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Evaluate model on test instances and compute test error\n"
   ]

  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "var predictionAndLabel = testData.mapToPair(function(p) {\n",
    "    return new Tuple(model.predict(p.getFeatures()), p.getLabel());\n",
    "});\n",
    "\n",
    "var testErr = 1.0 * predictionAndLabel.filter(function(tup) {\n",
    "    return (tup[0] !== tup[1]);\n",
    "}).count() \/ testData.count();\n",
    "\n",
    "print(\"Test Error: \" + testErr);\n",
    "print(\"Learned classification forest model:\\n\" + model.toDebugString());\n"
   ]

  },
   {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Save and load model\n",
    "model.save(sc, \"target\/tmp\/myRandomForestClassification\");\n",
    "var sameModel = RandomForestModel.load(\n",
    "    sc,\n",
    "    \"target\/tmp\/myRandomForestClassificationModel\"\n",
    ");\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark 1.6.1 (Javascript)",
   "language": "javascript",
   "name": "eclair"
  },
  "language_info": {
   "name": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}